Olá, hoje a nossa análise vai fundo em um tema fascinante, como é que a gente pode usar dados sobre pessoas, idade, escolaridade, até personalidade para tentar é prever a chance de consumir uma droga específica. O foco hoje é cannabis. OPA, tema complexo e super relevante? Pois é, e para guiar essa conversa, a gente está usando uns trechos de um guia conceitual de mestrado que trata justamente dessa previsão de consumo, certo? A ideia aqui é entender. Sabe como construir um sistema inteligente para fazer isso, focando na estratégia e nos dados que a gente tem. A pergunta chave é, quais características assim demográficas e de personalidade tem uma ligação mais forte com o uso de cannabis? Exato. E tecnicamente falando, o que a gente está encarando é uma tarefa de classificação binária. Classificação binária. O que seria isso na prática? É basicamente separar todo mundo em 2 grupos bem definidos. De um lado, os não usuários, que seriam pessoas que ou nunca usaram né? Que a fonte chama de CL zero ou usaram, mas tipo há mais de uma década OCL, um OK não usuários e o outro o outro são os usuários. Aí entra quem usou recentemente ou usa de forma contínua. Isso cobre as classes CL 2 até CL 6 do estudo original a. Meta é conseguir colocar cada pessoa em um desses 2 potes. Usa ou não usa? Basicamente entendi. E pra fazer essa divisão, quais são as pistas as features que o guia menciona usar? Olha, são as 12 colunas que vem no conjunto de dados inicial, tem idade, gênero, nível de educação, país, etnia e aí vem a partir da personalidade. Ah sim, aqueles schors n score e scorr. Espera aí, me ajuda a lembrar o que eles medem rapidinho, claro, são traços de personalidade bem estudados. Whey scor, por exemplo, é ligado ao neuroticismo coisas tipo ansiedade. Instabilidade emocional? O score mede extroversão o quão sociável a pessoa é, Oo score é abertura a novas experiências tem Oo score de amabilidade tipo o quão cooperativa a pessoa é, certo EOC score que mede conscienciosidade organização, disciplina, sabe? E além desses 5 grandes, o dera 7 ainda traz medidas de impulsividade e de busca por sensações. O SS, nossa, que mistura, Hein? Os demográficos com personalidade. E teve uma descoberta importante sobre o formato desses dados. Não é na fase de exploração, sim, exato, isso foi um ponto chave. Na fase 2, o guia ponto, que olha só, todas essas 12 colunas já estavam em formato numérico, como assim numérico tipo gênero não era masculino, feminino não era um número tipo zero, ponto 48, 246 e país também não era Reino Unido era, sei lá, zero. Ponto 9682. Tudo número caramba, até país e etnia. E isso é comum. A fonte explica. Porque fizeram isso. Será que foi para ananimizar? Então? O guia não detalha o motivo exato dessa codificação prévia. Pode ser anonimização, pode ser padronização. O resultado de como o questionário foi aplicado, né? Mas o impacto disso que é discutido na fase 3. E esse é gigante, imagino. Quer dizer então todo aquele trabalho de pré processamento que a gente sempre ouve falar, tipo ter que transformar a categorias como o ensino médio em números, os. Talvez usar aquela técnica one hot em coding, exatamente o one hoting coding que cria varias coluninhas de sim não isso e também o ajuste das escalas, o escalonamento ou normalização. Mesma faixa de valores, então nada disso foi preciso, nada. O daita 7 já veio, digamos, mastigado para os modelos. O trabalho nessa fase ficou bem mais simples, basicamente só checar se faltava algum dado e separar o que a gente usa para prever as pistas OX do que a gente quer prever o alvo. OY nossa, que atalho. Mas fico pensando transformar algo como personalidade ou mesmo etnia num número frio se. Não se perde um pouco da complexidade humana e no meio é uma ótima reflexão. É verdade, essa quantificação ajuda muito os algoritmos a achar padrões, né? Mas sempre existe o risco de simplificar demais a realidade. É um equilíbrio delicado entre o que é tecnicamente viável e o que representa fielmente a pessoa. Faz todo o sentido bom com os dados já prontinhos, como é que o guia sugere seguir para escolher e treinar os modelos a fase 4, né isso, a recomendação é usar uma técnica bem robusta. A validação cruzada cá *** cafod, como funciona? Imagina que você divide seus dados em, digamos, k igual a 10 partes iguais? Você vai treinar o modelo 10 vezes em cada vez. Você usa 9 partes para treinar e uma parte diferente a cada vez para testar. Ah, entendi, roda várias vezes com partes diferentes? Exato. Isso dá uma estimativa muito mais confiável do desempenho do modelo do que só dividiu uma vez em treino e teste, evita depender da sorte de uma única divisão. Parece bem sólido? Sim. E quais modelos o guia sugere colocar pra competir? Ouvi dizer que tinha uns apelidos engraçados. Tinham são 3 bem conhecidos. Primeiro, a regressão logística. O guia chama de o estatístico cauteloso, haha. Por quê? Porque o método mais tradicional estatístico mesmo e geralmente mais fácil de interpretar o que ele está fazendo, OKE, os outros. Depois vem a floresta aleatória ou o random forest. O apelido é a sabedoria da multidão, gostei é porque ela combina a decisão de muitas árvores de decisão simples. É como perguntar para um Monte de gente e pegar a resposta mais comum tende a ser bem robusta, interessante. E último, o último é OX ng boost, apelidado de O Mestre especialista. Esse é famoso por ganhar muitas competições de machine learning, costuma ter um desempenho muito alto. Mestre especialista, uau. E aí para saber qual desses o cauteloso, a multidão ou O Mestre se saiu melhor? Como a gente compara fase 5? Aí a gente avalia usando as médias das métricas que saíram da validação cruzada. A curácia é uma delas, o percentual geral de acertos OKA curacea é o mais óbvio, mas tem outras, né? Sim, são. E são importantes, precisam, por exemplo, ela responde. De todos que o modelo disse que são usuários, quantos realmente são? Ajuda a ver se o modelo está inventando muito. Entendi e recall, recall olha para o outro lado de todos que realmente são usuários dos dados quantos o modelo conseguiu achar. Ajuda a ver se o modelo está deixando passar muita gente e analisar a matriz de confusão que mostra os tipos de erro, tipo chamar um usuário de não usuário e vice versa também é fundamental. Ah, legal. Zoe, o recall. Focam em tipos diferentes de erro, então, e depois de escolher o modelo campeão, ainda tem a fase 6, que é interpretar, né? Não adianta só ter um modelo bom, exatamente, é crucial entender por que ele funciona, o que ele aprendeu. Se o modelo diz que uma feature numérica tipo educação, com valor de 0.454 68 é super importante para a previsão, esse número sozinho não diz muito, pois é, a gente precisa voltar. Na legenda dos dados, o guia mostra. Esse caso, esse valor 0.45468, corresponde a diploma universitário. Sem essa tradução, a descoberta do modelo fica abstrata, tem que conectar o número com o significado real perfeito. Então, resumindo a história toda, a mensagem principal que fica é que sim, é viável usar machine learning para investigar esses padrões de uso de substâncias e que o jeito como os dados são preparados pode. Facilitar muito a vida na parte técnica, exatamente. E o Gui até aponta próximos passos. Como testar isso para outras drogas, tipo cocaína ou nicotina? Window aumenta a complexidade em vez de só o usuário não usuário. Ver as 7 classes originais de frequência de uso ou, claro, tentar otimizar ainda mais os modelos. Muito caminho pela frente. E para fechar aquela reflexão que surgiu sobre transformar características humanas em números. Sim, acho que vale a pena deixar essa questão no ar quando a gente pega algo tão complexo como personalidade ou histórico de vida e traduz isso para números, para alimentar um algoritmo. Por mais útil que seja para achar padrões, que nuances que sutilezas da experiência humana podem acabar sendo talvez simplificadas demais ou até perdidas nesse processo de quantificação? É algo pra gente manter em mente a usar e interpretar esses resultados. 
